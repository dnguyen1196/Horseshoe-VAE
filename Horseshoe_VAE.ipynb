{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horseshoe-VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "qOLmcpS_0MJE"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnguyen1196/Horseshoe-VAE/blob/master/Horseshoe_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-fsaZQ4qqUxL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download KEGG file from drive\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D-GE8kpfgHoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "bce55148-f733-416b-c833-fd97d471ad10"
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1RwjZaMjdDmqceedNCu3VvGI3bqQQn9g2'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content KEGG file')\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "G = nx.read_gpickle(“kegg.ungraph.pkl”)\n",
        "\n",
        "for n in G.nodes:\n",
        "    print(“Fingerprints for node %s: %r” % (n, G.nodes[n][“fingerprint”]))\n",
        "    break"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded content KEGG file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LiB6j9qcB4L7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install torch\n",
        "\n",
        "NOTE:\n",
        "Compared to the reference VAE implementation, the main difference is in the calc_vi_loss function\n",
        "where the likelihood term has been augmented with the loss term to reconstruct the adjacency matrix\n"
      ]
    },
    {
      "metadata": {
        "id": "jHLhxy06GNQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the necssary packages\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IdhSSbsHzrsB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Standard VAE class"
      ]
    },
    {
      "metadata": {
        "id": "sYNQvpF8AQYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_dims_code=16,\n",
        "            n_dims_data=32,\n",
        "            hidden_layer_sizes=[32],\n",
        "            encoder=True,):\n",
        "        \n",
        "        \"\"\"\n",
        "        q_sigma = 0.2\n",
        "        \"\"\"\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        self.n_dims_data = n_dims_data\n",
        "        self.n_dims_code = n_dims_code\n",
        "        layer_sizes = (\n",
        "            [n_dims_data] + hidden_layer_sizes + [n_dims_code]\n",
        "        )\n",
        "        self.n_layers = len(layer_sizes) - 1\n",
        "\n",
        "        if not encoder:\n",
        "            layer_sizes = [a for a in reversed(layer_sizes)]\n",
        "\n",
        "        self.activations = list()\n",
        "        self.params = nn.ModuleList()\n",
        "        for (n_in, n_out) in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
        "            self.params.append(nn.Linear(n_in, n_out))\n",
        "            self.activations.append(F.relu)\n",
        "        self.activations[-1] = lambda a: a\n",
        "\n",
        "            \n",
        "    def forward(self, x):\n",
        "        # Note that if x contains multiple instance\n",
        "        # if x.shape = (num_sample, in_dim)\n",
        "        # then the output shape will be (num_sample, out_dim)\n",
        "        cur_arr = x\n",
        "        for ll in range(self.n_layers):\n",
        "            linear_func = self.params[ll]\n",
        "            a_func = self.activations[ll]\n",
        "            cur_arr = a_func(linear_func(cur_arr))\n",
        "        mu_NC = cur_arr\n",
        "        return mu_NC\n",
        "\n",
        "      \n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            q_sigma=0.2,\n",
        "            n_dims_code=16,\n",
        "            n_dims_data=64,\n",
        "            hidden_layer_sizes=[32],\n",
        "            hsp=False\n",
        "    ):\n",
        "\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.n_dims_data = n_dims_data\n",
        "        self.n_dims_code = n_dims_code\n",
        "        self.q_sigma = torch.Tensor([float(q_sigma)])\n",
        "        encoder_layer_sizes = (\n",
        "            [n_dims_data] + hidden_layer_sizes + [n_dims_code]\n",
        "        )\n",
        "        self.n_layers = len(encoder_layer_sizes) - 1\n",
        "        \n",
        "        if not hsp:\n",
        "            # Encoder network\n",
        "            self.encoder = NeuralNetwork(\n",
        "                n_dims_code=n_dims_code,\n",
        "                n_dims_data=n_dims_data,\n",
        "                hidden_layer_sizes=hidden_layer_sizes,\n",
        "                encoder=True,\n",
        "            )\n",
        "            # Decoder network\n",
        "            self.decoder = NeuralNetwork(\n",
        "                n_dims_code=n_dims_code,\n",
        "                n_dims_data=n_dims_data,\n",
        "                hidden_layer_sizes=hidden_layer_sizes,\n",
        "                encoder=False,\n",
        "            )\n",
        "        else:\n",
        "            # TODO: FactorizedInv-Gamma\n",
        "            # Use Ghosh's implementation of the factorizedInv-Gamma inference\n",
        "            # engine or reimplement his code with pytorch\n",
        "            \n",
        "            pass\n",
        "        \n",
        "\n",
        "    def forward(self, x_ND):\n",
        "        \"\"\"\n",
        "        Run entire probabilistic autoencoder on input (encode then decode)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        xproba_ND : 1D array, size of x_ND\n",
        "        \"\"\"\n",
        "        mu_NC = self.encode(x_ND)\n",
        "        z_NC = self.draw_sample_from_q(mu_NC)\n",
        "        return self.decode(z_NC), mu_NC\n",
        "\n",
        "    \n",
        "    def draw_sample_from_q(self, mu_NC):\n",
        "        ''' Draw sample from the probabilistic encoder q(z|mu(x), \\sigma)\n",
        "\n",
        "        We assume that \"q\" is Normal with:\n",
        "        * mean mu (argument of this function)\n",
        "        * stddev q_sigma (attribute of this class, use self.q_sigma)\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "        mu_NC : tensor-like, N x C\n",
        "            Mean of the encoding for each of the N images in minibatch.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        z_NC : tensor-like, N x C\n",
        "            Exactly one sample vector for each of the N images in minibatch.\n",
        "        '''\n",
        "        # Number of samples\n",
        "        N = mu_NC.shape[0]\n",
        "        \n",
        "        # The dimension of the code\n",
        "        C = self.n_dims_code\n",
        "\n",
        "        if self.training:\n",
        "            # Draw standard normal samples \"epsilon\"\n",
        "            # Use the reparameterization trick\n",
        "            eps_NC = torch.randn(N, C)\n",
        "            z_NC = mu_NC + eps_NC * self.q_sigma\n",
        "            return z_NC\n",
        "        else:\n",
        "            # For evaluations, we always just use the mean\n",
        "            return mu_NC\n",
        "\n",
        "    def encode(self, x_ND):\n",
        "        \"\"\"\n",
        "        Args\n",
        "        ----\n",
        "        x_ND: the observation vector\n",
        "        \"\"\"\n",
        "        return self.encoder.forward(x_ND)\n",
        "\n",
        "    def decode(self, z_NC):\n",
        "        \"\"\"\n",
        "        Args\n",
        "        ----\n",
        "        z_NC: the code vector\n",
        "        \"\"\"\n",
        "        return self.decoder.forward(z_NC)\n",
        "\n",
        "    def binary_predict_error_rate(self, f_predict, f_true):\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        length = f_predict.size()[0]\n",
        "        f_predict_binary = (f_predict > 0.5).type(torch.FloatTensor)\n",
        "        error = torch.sum((f_predict_binary - f_true).abs_()) / length\n",
        "        return error\n",
        "\n",
        "    def calc_vi_loss(self, xs_ND, ys_ND, vals, n_mc_samples=1):\n",
        "        \"\"\"\n",
        "        Args\n",
        "\n",
        "        xs_ND: the input feature vectors\n",
        "        ys_ND: the other feature vectors in mini-batch\n",
        "        vals: the entry associated with (x,y)\n",
        "        n_mc_samples: \n",
        "\n",
        "        ----\n",
        "        Returns:\n",
        "        loss\n",
        "\n",
        "        \"\"\"\n",
        "        neg_expected_ll = 0.0\n",
        "        # Given a (potentially) a tensor of observation vectors, \n",
        "        # Encode it into latent space\n",
        "        mx_NC = self.encode(xs_ND)\n",
        "        my_NC = self.encode(ys_ND)\n",
        "        \n",
        "        # Compute the KL divergence\n",
        "        # KL(N(mx_NC, q_sigma) || N(0, I))\n",
        "        kl_xz_NC = -0.5 * torch.sum(1 + torch.log(self.q_sigma ** 2) - mx_NC ** 2 - self.q_sigma ** 2)\n",
        "        kl_yz_NC = -0.5 * torch.sum(1 + torch.log(self.q_sigma ** 2) - my_NC ** 2 - self.q_sigma ** 2)\n",
        "        kl       = kl_xz_NC + kl_yz_NC # Total KL term\n",
        "        \n",
        "        # Generate samples from N(mx_NC, q_sigma) to compute the following\n",
        "        # E_q[log p(x_ND|mx_NC)]\n",
        "        for ss in range(n_mc_samples):\n",
        "            sample_z_NC      = self.draw_sample_from_q(mx_NC)\n",
        "            sample_xproba_ND = self.decode(sample_z_NC)\n",
        "\n",
        "            # Use MSE to measure reconstruction loss\n",
        "            # Since MSE is equivalent to log gaussian loss\n",
        "            sample_mse_loss  = F.mse_loss(sample_xproba_ND, xs_ND)\n",
        "\n",
        "            # KL divergence from q(mu, sigma) to prior (std normal)\n",
        "            neg_expected_ll += 1/n_mc_samples * sample_mse_loss\n",
        "        \n",
        "        \n",
        "        # Compute the loss from adjacency matrix reconstruction\n",
        "        # Get number of entries\n",
        "        num_samples = len(vals)\n",
        "        f_predict   = torch.zeros(num_samples)\n",
        "\n",
        "        # Compute\n",
        "        # E_q[log p(A_ij|x_i, x_j)] = E_q[Bern(A_ij|sigmoid(x_i dot x_j))]\n",
        "        \n",
        "        for ss in range(n_mc_samples):\n",
        "            # These two should have the same shape\n",
        "            # which is (N*C)\n",
        "            sample_z_NC = self.draw_sample_from_q(mx_NC)\n",
        "            sample_y_NC = self.draw_sample_from_q(my_NC)\n",
        "\n",
        "            # inner_prod.shape = (N,)\n",
        "            inner_prod  = torch.sum(sample_z_NC * sample_y_NC, dim=1)\n",
        "            f_predict  += 1/n_mc_samples * torch.sigmoid(inner_prod)\n",
        "\n",
        "        # Use binary cross entry loss, NOTE that this is for\n",
        "        # adjacency matrix whose entry values are 0 and 1\n",
        "        # This will need to change for other types of adjacency matrix value\n",
        "        # Use the binary prediction loss with logits\n",
        "        matrix_reconstruction_loss = \\\n",
        "            F.binary_cross_entropy(f_predict, Variable(torch.FloatTensor(vals)), reduction='sum')\n",
        "        \n",
        "        neg_expected_ll += matrix_reconstruction_loss\n",
        "        \n",
        "        return neg_expected_ll, kl, matrix_reconstruction_loss, sample_xproba_ND\n",
        "      \n",
        "      \n",
        "\n",
        "class VariationalAutoencoderHSP(VariationalAutoencoder):\n",
        "    def __init__(self,inference_engine,**kwargs,):\n",
        "\n",
        "        super(VariationalAutoencoderHSP, self).__init__(**kwargs)\n",
        "        assert inference_engine\n",
        "        self.inference_engine = inference_engine\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qOLmcpS_0MJE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# VAE with horseshoe priors"
      ]
    },
    {
      "metadata": {
        "id": "1cydvYRB0OqL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" Uses a non-centered parameterization of the model.\n",
        "    Fully factorized Gaussian + IGamma Variational distribution\n",
        "\tq = N(w_ijl | m_ijl, sigma^2_ijl) N(ln \\tau_kl | params) IGamma(\\lambda_kl| params)\n",
        "\tIGamma(\\tau_l | params) IGamma(\\lambda_l| params)\n",
        "\"\"\"\n",
        "\n",
        "import autograd.numpy as np\n",
        "import autograd.numpy.random as npr\n",
        "from autograd.scipy.misc import logsumexp\n",
        "from autograd.scipy.special import gammaln, psi\n",
        "from src.utility_functions import diag_gaussian_entropy, inv_gamma_entropy, log_normal_entropy\n",
        "\n",
        "\n",
        "class FactorizedHierarchicalInvGamma:\n",
        "    def __init__(self, n_weights, lambda_a, lambda_b, lambda_b_global, tau_a, shapes, train_stats, classification=False,\n",
        "                 n_data=None):\n",
        "        self.name = \"Factorized Hierarchical Inverse Gamma Variational Approximation\"\n",
        "        self.classification = classification\n",
        "        self.n_weights = n_weights\n",
        "        self.shapes = shapes\n",
        "        self.num_hidden_layers = len(shapes) - 1\n",
        "        self.lambda_a_prior = lambda_a\n",
        "        self.lambda_b_prior = lambda_b\n",
        "        self.lambda_a_prior_global = 0.5\n",
        "        self.lambda_b_prior_global = lambda_b_global\n",
        "        self.lambda_a_prior_oplayer = 0.5\n",
        "        self.lambda_b_prior_oplayer = 1.\n",
        "        self.tau_a_prior = tau_a\n",
        "        self.tau_a_prior_global = 0.5\n",
        "        self.tau_a_prior_oplayer = 0.5\n",
        "        self.l2pi = np.log(2 * np.pi)\n",
        "        self.n_data = n_data\n",
        "        self.noise_entropy = None\n",
        "        if not self.classification:\n",
        "            # gamma(6, 6) prior on precision\n",
        "            self.noise_a = 6.\n",
        "            self.noise_b = 6.\n",
        "            self.train_stats = train_stats\n",
        "\n",
        "    ######### PACK UNPACK PARAMS #################################################\n",
        "    def initialize_variational_params(self, param_scale=1):\n",
        "        # Initialize weights\n",
        "        wlist = list()\n",
        "        for m, n in self.shapes:\n",
        "            wlist.append(npr.randn(m * n) * np.sqrt(2 / m))\n",
        "            wlist.append(np.zeros(n))  # bias\n",
        "        w = np.concatenate(wlist)\n",
        "        log_sigma = param_scale * npr.randn(w.shape[0]) - 10.\n",
        "        # initialize scale parameters\n",
        "        self.tot_outputs = 0\n",
        "        for _, num_hl_outputs in self.shapes:\n",
        "            self.tot_outputs += num_hl_outputs\n",
        "        # No hs priors on the outputs\n",
        "        self.tot_outputs = self.tot_outputs - self.shapes[-1][1]\n",
        "        if not self.classification:\n",
        "            tau_mu, tau_log_sigma, tau_global_mu, tau_global_log_sigma, tau_oplayer_mu, tau_oplayer_log_sigma, log_a, \\\n",
        "                                log_b = self.initialize_scale_from_prior()\n",
        "            init_params = np.concatenate([w.ravel(), log_sigma.ravel(),\n",
        "                                          tau_mu.ravel(), tau_log_sigma.ravel(), tau_global_mu.ravel(),\n",
        "                                          tau_global_log_sigma.ravel(), tau_oplayer_mu, tau_oplayer_log_sigma, log_a,\n",
        "                                          log_b])\n",
        "        else:\n",
        "            tau_mu, tau_log_sigma, tau_global_mu, tau_global_log_sigma, tau_oplayer_mu, tau_oplayer_log_sigma = \\\n",
        "                self.initialize_scale_from_prior()\n",
        "            init_params = np.concatenate([w.ravel(), log_sigma.ravel(),\n",
        "                                          tau_mu.ravel(), tau_log_sigma.ravel(), tau_global_mu.ravel(),\n",
        "                                          tau_global_log_sigma.ravel(), tau_oplayer_mu, tau_oplayer_log_sigma])\n",
        "\n",
        "        return init_params\n",
        "\n",
        "    def initialize_scale_from_prior(self):\n",
        "        # scale parameters (hidden + observed),\n",
        "        self.lambda_a_hat = (self.tau_a_prior + self.lambda_a_prior) * np.ones([self.tot_outputs, 1]).ravel()\n",
        "        self.lambda_b_hat = (1.0 / self.lambda_b_prior ** 2) * np.ones([self.tot_outputs, 1]).ravel()\n",
        "        self.lambda_a_hat_global = (self.tau_a_prior_global + self.lambda_a_prior_global)  \\\n",
        "            * np.ones([self.num_hidden_layers, 1]).ravel()\n",
        "        self.lambda_b_hat_global = (1.0 / self.lambda_b_prior_global ** 2) * np.ones(\n",
        "            [self.num_hidden_layers, 1]).ravel()\n",
        "        # set oplayer lambda param\n",
        "        self.lambda_a_hat_oplayer = np.array(self.tau_a_prior_oplayer + self.lambda_a_prior_oplayer).reshape(-1)\n",
        "        self.lambda_b_hat_oplayer = (1.0 / self.lambda_b_prior_oplayer ** 2) * np.ones([1]).ravel()\n",
        "        # sample from half cauchy and log to initialize the mean of the log normal\n",
        "        sample = np.abs(self.lambda_b_prior * (npr.randn(self.tot_outputs) / npr.randn(self.tot_outputs)))\n",
        "        tau_mu = np.log(sample)\n",
        "        tau_log_sigma = npr.randn(self.tot_outputs) - 10.\n",
        "        # one tau_global for each hidden layer\n",
        "        sample = np.abs(\n",
        "            self.lambda_b_prior_global * (npr.randn(self.num_hidden_layers) / npr.randn(self.num_hidden_layers)))\n",
        "        tau_global_mu = np.log(sample)\n",
        "        tau_global_log_sigma = npr.randn(self.num_hidden_layers) - 10.\n",
        "        # one tau for all op layer weights\n",
        "        sample = np.abs(self.lambda_b_hat_oplayer * (npr.randn() / npr.randn()))\n",
        "        tau_oplayer_mu = np.log(sample)\n",
        "        tau_oplayer_log_sigma = npr.randn(1) - 10.\n",
        "        if not self.classification:\n",
        "            log_a = np.array(np.log(self.noise_a)).reshape(-1)\n",
        "            log_b = np.array(np.log(self.noise_b)).reshape(-1)\n",
        "            return tau_mu, tau_log_sigma, tau_global_mu, tau_global_log_sigma, tau_oplayer_mu, tau_oplayer_log_sigma, \\\n",
        "                   log_a, log_b\n",
        "        else:\n",
        "            return tau_mu, tau_log_sigma, tau_global_mu, tau_global_log_sigma, tau_oplayer_mu, tau_oplayer_log_sigma\n",
        "\n",
        "    def unpack_params(self, params):\n",
        "        # unpack params\n",
        "        w_vect = params[:self.n_weights]\n",
        "        num_std = 2 * self.n_weights\n",
        "        sigma = np.log(1 + np.exp(params[self.n_weights:num_std]))\n",
        "        tau_mu = params[num_std:num_std + self.tot_outputs]\n",
        "        tau_sigma = np.log(\n",
        "            1 + np.exp(params[num_std + self.tot_outputs:num_std + 2 * self.tot_outputs]))\n",
        "        tau_mu_global = params[num_std + 2 * self.tot_outputs: num_std + 2 * self.tot_outputs + self.num_hidden_layers]\n",
        "        tau_sigma_global = np.log(1 + np.exp(params[num_std + 2 * self.tot_outputs + self.num_hidden_layers:num_std +\n",
        "                                                                    2 * self.tot_outputs + 2 * self.num_hidden_layers]))\n",
        "        tau_mu_oplayer = params[num_std + 2 * self.tot_outputs + 2 * self.num_hidden_layers: num_std +\n",
        "                                                                2 * self.tot_outputs + 2 * self.num_hidden_layers + 1]\n",
        "        tau_sigma_oplayer = np.log(\n",
        "            1 + np.exp(params[num_std + 2 * self.tot_outputs + 2 * self.num_hidden_layers + 1:]))\n",
        "        if not self.classification:\n",
        "            a = tau_sigma_oplayer[1]\n",
        "            b = tau_sigma_oplayer[2]\n",
        "            tau_sigma_oplayer = tau_sigma_oplayer[0]\n",
        "            egamma = a / b\n",
        "            elog_gamma = psi(a) - np.log(b)\n",
        "            self.noise_entropy = inv_gamma_entropy(a, b)\n",
        "            #  we will just use a point estimate of noise_var b/a+1 (noise_var ~ IGamma) for computing predictive ll\n",
        "            self.noisevar = (b / (a + 1)) * self.train_stats['sigma'] ** 2\n",
        "            return w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, \\\n",
        "                   tau_sigma_oplayer, elog_gamma, egamma\n",
        "        else:\n",
        "            return w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer\n",
        "\n",
        "    def unpack_layer_weight_variances(self, sigma_vect):\n",
        "        for m, n in self.shapes:\n",
        "            yield sigma_vect[:m * n].reshape((m, n)), sigma_vect[m * n:m * n + n]\n",
        "            sigma_vect = sigma_vect[(m + 1) * n:]\n",
        "\n",
        "    def unpack_layer_weight_priors(self, tau_vect):\n",
        "        for m, n in self.shapes:\n",
        "            yield tau_vect[:n]\n",
        "            tau_vect = tau_vect[n:]\n",
        "\n",
        "    def unpack_layer_weights(self, w_vect):\n",
        "        for m, n in self.shapes:\n",
        "            yield w_vect[:m * n].reshape((m, n)), w_vect[m * n:m * n + n]\n",
        "            w_vect = w_vect[(m + 1) * n:]\n",
        "\n",
        "    ######### Fixed Point Updates ################################## #####\n",
        "    def fixed_point_updates(self, params):\n",
        "        if self.classification:\n",
        "            w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer = \\\n",
        "                self.unpack_params(params)\n",
        "        else:\n",
        "            w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, _, _ \\\n",
        "                = self.unpack_params(params)\n",
        "        # update lambda moments\n",
        "        self.lambda_b_hat = np.exp(-tau_mu + 0.5 * tau_sigma ** 2) + (1. / self.lambda_b_prior ** 2)\n",
        "        self.lambda_b_hat_global = np.exp(-tau_mu_global + 0.5 * tau_sigma_global ** 2) + (\n",
        "            1. / self.lambda_b_prior_global ** 2)\n",
        "        self.lambda_b_hat_oplayer = np.exp(-tau_mu_oplayer + 0.5 * tau_sigma_oplayer ** 2) + (\n",
        "            1. / self.lambda_b_prior_oplayer ** 2)\n",
        "        return None\n",
        "\n",
        "    ######### ELBO CALC ################################################\n",
        "    def lrpm_forward_pass(self, mu_vect, sigma_vect, tau_mu_vect, tau_sigma_vect, tau_mu_global, tau_sigma_global,\n",
        "                          tau_mu_oplayer, tau_sigma_oplayer, inputs):\n",
        "        for layer_id, (mu, var, tau_mu, tau_sigma) in enumerate(\n",
        "                zip(self.unpack_layer_weights(mu_vect), self.unpack_layer_weight_variances(sigma_vect),\n",
        "                    self.unpack_layer_weight_priors(tau_mu_vect),\n",
        "                    self.unpack_layer_weight_priors(tau_sigma_vect))):\n",
        "            w, b = mu\n",
        "            sigma__w, sigma_b = var\n",
        "            if layer_id < len(self.shapes) - 1:\n",
        "                scale_mu = 0.5 * (tau_mu + tau_mu_global[layer_id])\n",
        "                scale_v = 0.25 * (tau_sigma ** 2 + tau_sigma_global[layer_id] ** 2)\n",
        "                scale = np.exp(scale_mu + np.sqrt(scale_v) * npr.randn(tau_mu.shape[0]))\n",
        "                mu_w = np.dot(inputs, w) + b\n",
        "                v_w = np.dot(inputs ** 2, sigma__w ** 2) + sigma_b ** 2\n",
        "                outputs = (np.sqrt(v_w) / np.sqrt(inputs.shape[1])) * np.random.normal(size=mu_w.shape) + mu_w\n",
        "                outputs = scale * outputs\n",
        "                inputs = outputs * (outputs > 0)\n",
        "            else:\n",
        "                op_scale_mu = 0.5 * tau_mu_oplayer\n",
        "                op_scale_v = 0.25 * tau_sigma_oplayer ** 2\n",
        "                Ekappa_half = np.exp(op_scale_mu + np.sqrt(op_scale_v) * npr.randn())\n",
        "                mu_w = np.dot(inputs, w) + b\n",
        "                v_w = np.dot(inputs ** 2, sigma__w ** 2) + sigma_b ** 2\n",
        "                outputs = Ekappa_half * (np.sqrt(v_w) / np.sqrt(inputs.shape[1])) * np.random.normal(\n",
        "                    size=mu_w.shape) + mu_w\n",
        "        return outputs\n",
        "\n",
        "    def EPw_Gaussian(self, prior_precision, w, sigma):\n",
        "        \"\"\"\"\\int q(z) log p(z) dz, assuming gaussian q(z) and p(z)\"\"\"\n",
        "        wD = w.shape[0]\n",
        "        prior_wvar_ = 1. / prior_precision\n",
        "        a = - 0.5 * wD * np.log(2 * np.pi) - 0.5 * wD * np.log(prior_wvar_) - 0.5 * prior_precision * (\n",
        "            np.dot(w.T, w) + np.sum((sigma ** 2)))\n",
        "        return a\n",
        "\n",
        "    def EP_Gamma(self, Egamma, Elog_gamma):\n",
        "        \"\"\" Enoise precision \"\"\"\n",
        "        return self.noise_a * np.log(self.noise_b) - gammaln(self.noise_a) + (\n",
        "                                                            - self.noise_a - 1) * Elog_gamma - self.noise_b * Egamma\n",
        "\n",
        "    def EPtaulambda(self, tau_mu, tau_sigma, tau_a_prior, lambda_a_prior,\n",
        "                    lambda_b_prior, lambda_a_hat, lambda_b_hat):\n",
        "        \"\"\" E[ln p(\\tau | \\lambda)] + E[ln p(\\lambda)]\"\"\"\n",
        "        etau_given_lambda = -gammaln(tau_a_prior) - tau_a_prior * (np.log(lambda_b_hat) - psi(lambda_a_hat)) + (\n",
        "                            -tau_a_prior - 1.) * tau_mu - np.exp(-tau_mu + 0.5 * tau_sigma ** 2) * (lambda_a_hat /\n",
        "                                               lambda_b_hat)\n",
        "        elambda = -gammaln(lambda_a_prior) - 2 * lambda_a_prior * np.log(lambda_b_prior) + (-lambda_a_prior - 1.) * (\n",
        "            np.log(lambda_b_hat) - psi(lambda_a_hat)) - (1. / lambda_b_prior ** 2) * (lambda_a_hat / lambda_b_hat)\n",
        "        return np.sum(etau_given_lambda) + np.sum(elambda)\n",
        "\n",
        "    def entropy(self, sigma, tau_sigma, tau_mu, tau_sigma_global, tau_mu_global, tau_sigma_oplayer, tau_mu_oplayer):\n",
        "        ent_w = diag_gaussian_entropy(np.log(sigma), self.n_weights)\n",
        "        ent_tau = log_normal_entropy(np.log(tau_sigma), tau_mu, self.tot_outputs) + log_normal_entropy(\n",
        "            np.log(tau_sigma_global), tau_mu_global, self.num_hidden_layers) + log_normal_entropy(\n",
        "            np.log(tau_sigma_oplayer), tau_mu_oplayer, 1)\n",
        "        ent_lambda = inv_gamma_entropy(self.lambda_a_hat, self.lambda_b_hat) + inv_gamma_entropy(\n",
        "            self.lambda_a_hat_global, self.lambda_b_hat_global) + inv_gamma_entropy(self.lambda_a_hat_oplayer,\n",
        "                                                                                    self.lambda_b_hat_oplayer)\n",
        "        return ent_w, ent_tau, ent_lambda\n",
        "\n",
        "    def compute_elbo_contribs(self, params, x, y):\n",
        "        if self.classification:\n",
        "            w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer \\\n",
        "                = self.unpack_params(params)\n",
        "        else:\n",
        "            w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, \\\n",
        "            Elog_gamma, Egamma = self.unpack_params(params)\n",
        "        preds = self.lrpm_forward_pass(w_vect, sigma, tau_mu, tau_sigma,\n",
        "                                       tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, x)\n",
        "        if self.classification:\n",
        "            preds = preds - logsumexp(preds, axis=1, keepdims=True)\n",
        "            log_lik = np.sum(np.sum(y * preds, axis=1), axis=0)\n",
        "        else:\n",
        "            log_lik = -0.5 * np.sum((preds - y.reshape(-1, 1)) ** 2) * Egamma - 0.5 * preds.shape[0] * self.l2pi \\\n",
        "                      + 0.5 * preds.shape[0] * Elog_gamma\n",
        "\n",
        "        log_prior = self.EPw_Gaussian(1., w_vect, sigma)\n",
        "        log_prior = log_prior + \\\n",
        "                    self.EPtaulambda(tau_mu, tau_sigma, self.tau_a_prior, self.lambda_a_prior, self.lambda_b_prior,\n",
        "                                     self.lambda_a_hat, self.lambda_b_hat) + \\\n",
        "                    self.EPtaulambda(tau_mu_global, tau_sigma_global, self.tau_a_prior_global,\n",
        "                                     self.lambda_a_prior_global, self.lambda_b_prior_global, self.lambda_a_hat_global,\n",
        "                                     self.lambda_b_hat_global) + \\\n",
        "                    self.EPtaulambda(tau_mu_oplayer, tau_sigma_oplayer, self.tau_a_prior_oplayer,\n",
        "                                     self.lambda_a_prior_oplayer, self.lambda_b_prior_oplayer,\n",
        "                                     self.lambda_a_hat_oplayer, self.lambda_b_hat_oplayer)\n",
        "        ent_w, ent_tau, ent_lambda = self.entropy(sigma, tau_sigma, tau_mu, tau_sigma_global, tau_mu_global,\n",
        "                                                  tau_sigma_oplayer, tau_mu_oplayer)\n",
        "\n",
        "        if not self.classification:\n",
        "            log_prior = log_prior + self.EP_Gamma(Egamma, Elog_gamma)\n",
        "            ent_lambda = ent_lambda + self.noise_entropy  # hack add it to lambda entropy\n",
        "        return log_lik, log_prior, ent_w, ent_tau, ent_lambda\n",
        "\n",
        "\n",
        "    def compute_train_err(self, params, X, y):\n",
        "        if self.classification:\n",
        "            W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer = \\\n",
        "                self.unpack_params(params)\n",
        "        else:\n",
        "            W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, _, _ \\\n",
        "                = self.unpack_params(params)\n",
        "        preds = self.lrpm_forward_pass(W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global,\n",
        "                                       tau_mu_oplayer, tau_sigma_oplayer, X)\n",
        "        if self.classification:\n",
        "            preds = np.exp(preds - logsumexp(preds, axis=1, keepdims=True))\n",
        "            tru_labels = np.argmax(y, axis=1)\n",
        "            pred_labels = np.argmax(preds, axis=1)\n",
        "            err_ids = tru_labels != pred_labels\n",
        "            return 1. * np.sum(err_ids) / y.shape[0]\n",
        "        else:\n",
        "            return np.sqrt(np.mean((preds - y.reshape(-1, 1)) ** 2))\n",
        "\n",
        "    def compute_test_ll(self, params, x, y_test, num_samples=1):\n",
        "        if self.classification:\n",
        "            W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer = \\\n",
        "                self.unpack_params(params)\n",
        "        else:\n",
        "            W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, \\\n",
        "            Elog_gamma, Egamma = self.unpack_params(params)\n",
        "        err_rate = 0.\n",
        "        test_ll = np.zeros([num_samples, y_test.shape[0]])\n",
        "        test_ll_dict = dict()\n",
        "        for i in np.arange(num_samples):\n",
        "            y = self.lrpm_forward_pass(W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global,\n",
        "                                       tau_mu_oplayer, tau_sigma_oplayer, x)\n",
        "            if y_test.ndim == 1:\n",
        "                y = y.ravel()\n",
        "            if self.classification:\n",
        "                yraw = y - logsumexp(y, axis=1, keepdims=True)\n",
        "                y = np.exp(yraw)\n",
        "                tru_labels = np.argmax(y_test, axis=1)\n",
        "                pred_labels = np.argmax(y, axis=1)\n",
        "                err_ids = tru_labels != pred_labels\n",
        "                err_rate = err_rate + np.sum(err_ids) / y_test.shape[0]\n",
        "                # test_ll is scaled by number of test_points\n",
        "                test_ll[i] = np.mean(np.sum(y_test * np.log(y + 1e-32), axis=1))\n",
        "            else:\n",
        "                # scale by target stats\n",
        "                y_scaled = y * self.train_stats['sigma'] + self.train_stats['mu']\n",
        "                # rmse\n",
        "                err_rate = err_rate + np.sqrt(np.mean((y_test - y_scaled) ** 2))\n",
        "                test_ll[i] = (-0.5 * (1. / self.noisevar) * (y_test - y_scaled) ** 2 - 0.5 * self.l2pi - 0.5 * np.log(\n",
        "                    self.noisevar)).ravel()\n",
        "\n",
        "        err_rate = err_rate / num_samples\n",
        "        test_ll_dict['mu'] = np.mean(logsumexp(test_ll, axis=0) - np.log(num_samples))\n",
        "        return test_ll_dict, err_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E72JYLr6TbU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Synthetic data generation\n",
        "\n",
        "Synthetic data (and real life data to test on) should include\n",
        "* Adjancency matrix (which might be sparse) where A_{ij} = 1 if there is an edge and 0 otherwise between two nodes i and j\n",
        "* The feature vectors for all the nodes"
      ]
    },
    {
      "metadata": {
        "id": "S8h-eAoXKYTu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_entry_values(coordinates, latent_vectors):\n",
        "    \"\"\"\n",
        "    coordinates: list of coordinates\n",
        "    \n",
        "    \"\"\"\n",
        "    vals    = list()\n",
        "    for i, j in coordinates:\n",
        "        if np.sum(latent_vectors[i] * latent_vectors[j]) > 0:\n",
        "            vals.append(1)\n",
        "        else:\n",
        "            vals.append(0)\n",
        "    return vals\n",
        "    \n",
        "\n",
        "def create_sparse_matrix_list(observed_coordinates, num_nodes, latent_vectors):\n",
        "    \"\"\"\n",
        "    observed_coordinates: list of (row,col) coordinates\n",
        "    num_nodes : int, number of nodes\n",
        "    latent_vectors : latent vectos whose inner products used to determine adjacency\n",
        "    matrix\n",
        "    \n",
        "    ---\n",
        "    return the sparse representation of the adjacency matrix\n",
        "    \n",
        "    \"\"\"\n",
        "    sparse_adjacency_matrix = [[] for _ in range(num_nodes)]\n",
        "\n",
        "    for entry in observed_coordinates:\n",
        "        idx, idy = entry[0], entry[1]\n",
        "        inner = np.dot(latent_vectors[idx, :], latent_vectors[idy, :])\n",
        "        val = 0\n",
        "        if inner > 0:\n",
        "            val = 1\n",
        "\n",
        "        sparse_adjacency_matrix[idx].append((entry, val))\n",
        "        sparse_adjacency_matrix[idy].append(([idy, idx], val))\n",
        "\n",
        "    return sparse_adjacency_matrix\n",
        "\n",
        "\n",
        "def create_observed_features(latent_vectors, num_nodes, true_dim, observed_dim, noise_feature_num=0):\n",
        "    \"\"\"    \n",
        "    latent_vectors : shape(num_nodes, true_dim), the latent feature vectors of all nodes\n",
        "    num_nodes : int, number of nodes in this network\n",
        "    true_dim  : int, dimension of the latent feature (the code)\n",
        "    observed_dim : int, dimension of the observed feature vector\n",
        "    num_noisy_dim : int, added noisy dimension\n",
        "    \n",
        "    ---\n",
        "    \n",
        "    Create observed features that contain both true and noisy features\n",
        "\n",
        "    1. Create a random transformation matrix A\n",
        "    2. Apply the transformation A X_l where X_l is the latent feature vectors\n",
        "    3. \n",
        "    ---\n",
        "    returns\n",
        "    \n",
        "    augmented_feature_matrix : shape(num_nodes, observed_dim + num_noisy_dim)\n",
        "    the augmented observed feature vector for all the nodes, with relevent\n",
        "    dimensions together with noisy entries.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Create a random transformation, A\n",
        "    transformation_matrix = np.random.randn(observed_dim, true_dim)\n",
        "\n",
        "    # X_true = dot(A, x_true)\n",
        "    transformed_feature = np.dot(transformation_matrix, latent_vectors.T)\n",
        "    transformed_feature = transformed_feature.T\n",
        "    transformed_feature /= transformed_feature.max()  # Scale the feature vectors by dividing by the max value\n",
        "\n",
        "    # If no noisy feature, just return the transformed feature\n",
        "    if noise_feature_num == 0:\n",
        "        return transformed_feature\n",
        "    \n",
        "    # If there are noisy features, generate these from standard normal distribution\n",
        "    # Noise feature = N(0, I)\n",
        "    # Create noise matrix X_noise\n",
        "    noise_feature_matrix = np.random.randn(num_nodes, noise_feature_num)\n",
        "    augmented_dim = observed_dim + noise_feature_num\n",
        "\n",
        "    # Horizontally concatenate X_true :: X_noise\n",
        "    augmented_feature_matrix = np.hstack((transformed_feature, noise_feature_matrix))\n",
        "\n",
        "    # Permute the features column\n",
        "    augmented_feature_matrix = augmented_feature_matrix[:, np.random.permutation(augmented_dim)]\n",
        "    return augmented_feature_matrix\n",
        "\n",
        "\n",
        "def create_synthetic_data(num_nodes, sparsity, true_dim, observed_dim, num_noisy_dim):\n",
        "    \"\"\"\n",
        "    num_nodes : int, number of nodes in this network\n",
        "    sparsity  : float, ratio of all entries, which are observed\n",
        "    true_dim  : int, dimension of the latent feature (the code)\n",
        "    observed_dim : int, dimension of the observed feature vector\n",
        "    num_noisy_dim : int, added noisy dimension\n",
        "    \n",
        "    --- \n",
        "    returns\n",
        "    \n",
        "    (latent_vectors, observed_feature_vectors, sparse_adjancency_matrix)\n",
        "    \n",
        "    latent_vectors : shape(num_nodes, true_dim), all the latent feature vectors\n",
        "    observed_feature_vectors : shape(num_nodes, observed_dim), all the observed feature vectors\n",
        "    sparse_adjancency_matrix : list[list(entry, value)] \n",
        "    \n",
        "    \"\"\"\n",
        "    # Create num_nodes hidden vector randomly\n",
        "    latent_vectors = np.random.multivariate_normal(np.zeros((true_dim,)), \\\n",
        "                                                   np.eye(true_dim), \\\n",
        "                                                   size=(num_nodes,))\n",
        "\n",
        "    coordinates = [[x,y] for x in range(num_nodes) for y in range(x+1, num_nodes)]\n",
        "    total_num_pairs = len(coordinates)\n",
        "    num_observed = int(len(coordinates) * sparsity)\n",
        "\n",
        "    # Pick a number of random coordinates\n",
        "    observed_idx = np.random.choice(total_num_pairs, num_observed, replace=False)\n",
        "    observed_coordinates = np.take(coordinates, observed_idx, axis=0)\n",
        "    \n",
        "    train_size = int(len(observed_coordinates) * 0.8)\n",
        "    train_coordinates = observed_coordinates[:train_size]\n",
        "    test_coordinates = observed_coordinates[train_size+1:]\n",
        "    \n",
        "    # Create sparse matrix representation\n",
        "    train_sparse_adjacency_matrix = create_sparse_matrix_list(train_coordinates, num_nodes, latent_vectors)\n",
        "    test_sparse_adjacency_matrix = create_sparse_matrix_list(test_coordinates, num_nodes, latent_vectors)\n",
        "    \n",
        "    # Create test matrix and train matrix\n",
        "    observed_feature_vectors = create_observed_features(latent_vectors, num_nodes, true_dim, observed_dim,\n",
        "                                                        num_noisy_dim)\n",
        "\n",
        "    return latent_vectors, observed_feature_vectors, train_sparse_adjacency_matrix, test_sparse_adjacency_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vr8CH4BrKL6v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Do training\n",
        "\n",
        "TODO:\n",
        "* Update the training function, first generate synthetic data, organize into batches\n",
        "* Compare between round-robin updates (aka update each row by row where the list of observations always share a common row index) vs mini-batch update where the list of observations can contain any random pair of two indices.\n"
      ]
    },
    {
      "metadata": {
        "id": "_xDkRxRa3mI4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation function"
      ]
    },
    {
      "metadata": {
        "id": "jBpBZKEVQuiX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to do evaluation\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def classification_accuracy(model, feature_tensor, adjacency_matrix, report=False):\n",
        "    \"\"\"\n",
        "    Feature vectors.shape -> (num_nodes, number of observed features)\n",
        "    adjancency_matrix -> sparse representation of adjancey matrix\n",
        "    where each row -> list of (coordinates, value) associated with the specific\n",
        "    factor\n",
        "\n",
        "    Uses model.encode(feature_vector)\n",
        "    \"\"\"\n",
        "    latent_vectors = model.encode(feature_tensor)\n",
        "    latent_adj_mat = torch.mm(latent_vectors, latent_vectors.transpose(0 , 1))\n",
        "    num_accurate = 0.0\n",
        "    num_observed = 0.0\n",
        "    for row in adjacency_matrix:\n",
        "        for coor, val in row:\n",
        "            if (\n",
        "                latent_adj_mat[coor[0]][coor[1]].item() < 0.0 and val == 0.0 or\n",
        "                latent_adj_mat[coor[0]][coor[1]].item() >= 0.0 and val == 1.0\n",
        "            ):\n",
        "\n",
        "                if report:\n",
        "                    print(\"predict: \", latent_adj_mat[coor[0]][coor[1]].item(), \" val: \", val)\n",
        "\n",
        "                num_accurate += 1\n",
        "            num_observed += 1\n",
        "\n",
        "    return num_accurate/ num_observed\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bt80bWYI3pHq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "EJ4zwglopm5E",
        "colab_type": "code",
        "outputId": "cf7aac87-8a64-4212-9bb4-65de4cf3cb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1338
        }
      },
      "cell_type": "code",
      "source": [
        "def train_on_synthetic_data(model, num_nodes, observed_dim, true_dim, fake_dim):\n",
        "    sparsity = 0.25\n",
        "    true_vectors, feature_vectors, train_adjacency_matrix, test_adjacency_matrix\\\n",
        "                = create_synthetic_data(num_nodes, sparsity, true_dim, observed_dim,\n",
        "                                                                            fake_dim)\n",
        "\n",
        "    # NOTE that there exists the 'interchangeability problem'\n",
        "    # XR^TRX = X^TX\n",
        "    # Y = XR^T\n",
        "    \n",
        "    # Initialize optimizer\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    obj_losses = []\n",
        "    epochs = []\n",
        "    all_epochs = []\n",
        "\n",
        "    for epoch in range(1001): \n",
        "        # Do round-robin optimization\n",
        "        for idx in range(num_nodes):\n",
        "            x_ND = Variable(torch.FloatTensor([feature_vectors[idx, :]]))\n",
        "            ys_ND = list()\n",
        "            observed_entries = train_adjacency_matrix[idx]\n",
        "            other_vec_idx = [entry[0][1] for entry in observed_entries]\n",
        "            vals = [entry[1] for entry in observed_entries]\n",
        "\n",
        "            for idy in other_vec_idx:\n",
        "                ys_ND.append(feature_vectors[idy, :])\n",
        "\n",
        "            ys_ND = Variable(torch.FloatTensor(ys_ND))\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # NOTE:\n",
        "            # expected_ll refers to the expected log likelihood term of ELBO\n",
        "            # kl refers to the KL divergence term of the ELBO\n",
        "            # matrix_loss refers to the matrix reconstruction loss\n",
        "            neg_expected_ll, KL, matrix_loss, _ = model.calc_vi_loss(x_ND, ys_ND, vals, n_mc_samples=10)\n",
        "            \n",
        "            KL = 1/len(observed_entries) * KL\n",
        "            # TODO: scale the KL term\n",
        "            # ELBO loss = negative expected log likelihood + KL\n",
        "            elbo_loss = neg_expected_ll + KL\n",
        "            \n",
        "            elbo_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        if epoch % 10 == 0:\n",
        "            all_epochs.append(epoch)\n",
        "            ELBOs.append(-elbo_loss)\n",
        "            \n",
        "\n",
        "        if epoch in [0, 1, 25] or epoch % 50 == 0:\n",
        "            all_vectors = Variable(torch.FloatTensor(feature_vectors))\n",
        "            train_accuracy = classification_accuracy(model, all_vectors, train_adjacency_matrix)\n",
        "            test_accuracy = classification_accuracy(model, all_vectors, test_adjacency_matrix)\n",
        "            epochs.append(epoch)\n",
        "            train_losses.append(train_accuracy)\n",
        "            test_losses.append(test_accuracy)\n",
        "            \n",
        "            print(\"epoch: \", epoch, \" - objective loss: \", np.around(elbo_loss.data.item(),4), \" - train accuracy: \",\n",
        "                  np.around(train_accuracy,4), \" - test accuracy: \", np.around(test_accuracy, 4))\n",
        "\n",
        "\n",
        "    plt.plot(epochs, train_losses, '-', color='b', label='Link predict accuracy on train data')\n",
        "    plt.plot(epochs, test_losses, '--', color='r', label='Link predict accuracy on test data')\n",
        "    plt.ylim((0, 1))\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(all_epochs, ELBOs, '-', color='r', label='ELBO')\n",
        "    plt.ylabel('ELBO value')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "num_nodes = 100\n",
        "observed_dim = 10\n",
        "true_dim = 3\n",
        "num_fake_dim = 5\n",
        "\n",
        "hidden_layer_sizes = [300]\n",
        "naive_model = VariationalAutoencoder(n_dims_code=5, \\\n",
        "                               n_dims_data=observed_dim+num_fake_dim, \\\n",
        "                               hidden_layer_sizes=hidden_layer_sizes)\n",
        "\n",
        "train_on_synthetic_data(naive_model, num_nodes, observed_dim, true_dim, num_fake_dim)\n",
        "\n",
        "# inference_engine = FactorizedHierarchicalInvGamma\n",
        "# hsbnn_model = VariationalAutoencoderHSP(inference_engine,\n",
        "#                                n_dims_code=5, \\\n",
        "#                                n_dims_data=observed_dim+num_fake_dim, \\\n",
        "#                                hidden_layer_sizes=hidden_layer_sizes)\n",
        "# train_on_synthetic_data(hsbnn_model, num_nodes, observed_dim, true_dim, num_fake_dim)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0  - objective loss:  23.1623  - train accuracy:  0.7735  - test accuracy:  0.7368\n",
            "epoch:  1  - objective loss:  21.163  - train accuracy:  0.8241  - test accuracy:  0.8178\n",
            "epoch:  25  - objective loss:  15.4048  - train accuracy:  0.9535  - test accuracy:  0.915\n",
            "epoch:  50  - objective loss:  14.2005  - train accuracy:  0.9575  - test accuracy:  0.9109\n",
            "epoch:  100  - objective loss:  13.836  - train accuracy:  0.9727  - test accuracy:  0.915\n",
            "epoch:  150  - objective loss:  12.5918  - train accuracy:  0.9737  - test accuracy:  0.8907\n",
            "epoch:  200  - objective loss:  12.6197  - train accuracy:  0.9909  - test accuracy:  0.8947\n",
            "epoch:  250  - objective loss:  12.8238  - train accuracy:  0.9899  - test accuracy:  0.8988\n",
            "epoch:  300  - objective loss:  12.8474  - train accuracy:  0.9869  - test accuracy:  0.8907\n",
            "epoch:  350  - objective loss:  12.7671  - train accuracy:  0.9919  - test accuracy:  0.8826\n",
            "epoch:  400  - objective loss:  12.8622  - train accuracy:  0.9889  - test accuracy:  0.8785\n",
            "epoch:  450  - objective loss:  12.8119  - train accuracy:  0.9919  - test accuracy:  0.8785\n",
            "epoch:  500  - objective loss:  12.6062  - train accuracy:  0.9909  - test accuracy:  0.8866\n",
            "epoch:  550  - objective loss:  12.7048  - train accuracy:  0.9869  - test accuracy:  0.8826\n",
            "epoch:  600  - objective loss:  12.8534  - train accuracy:  0.9889  - test accuracy:  0.8583\n",
            "epoch:  650  - objective loss:  12.4422  - train accuracy:  0.9939  - test accuracy:  0.8745\n",
            "epoch:  700  - objective loss:  12.7772  - train accuracy:  0.9949  - test accuracy:  0.8623\n",
            "epoch:  750  - objective loss:  12.2515  - train accuracy:  0.9919  - test accuracy:  0.8704\n",
            "epoch:  800  - objective loss:  12.6255  - train accuracy:  0.9869  - test accuracy:  0.8543\n",
            "epoch:  850  - objective loss:  12.9739  - train accuracy:  0.9899  - test accuracy:  0.8745\n",
            "epoch:  900  - objective loss:  12.8897  - train accuracy:  0.9889  - test accuracy:  0.8502\n",
            "epoch:  950  - objective loss:  12.6857  - train accuracy:  0.9879  - test accuracy:  0.8664\n",
            "epoch:  1000  - objective loss:  12.5097  - train accuracy:  0.9929  - test accuracy:  0.8664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFcCAYAAADh1zYWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f60749c6a58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFYCAYAAAB+s6Q9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f60748cb5c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VariationalAutoencoder(\n",
              "  (encoder): NeuralNetwork(\n",
              "    (params): ModuleList(\n",
              "      (0): Linear(in_features=15, out_features=300, bias=True)\n",
              "      (1): Linear(in_features=300, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): NeuralNetwork(\n",
              "    (params): ModuleList(\n",
              "      (0): Linear(in_features=5, out_features=300, bias=True)\n",
              "      (1): Linear(in_features=300, out_features=15, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}