{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horseshoe-VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "qOLmcpS_0MJE"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnguyen1196/Horseshoe-VAE/blob/master/Horseshoe_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-fsaZQ4qqUxL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download KEGG file from drive\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D-GE8kpfgHoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1RwjZaMjdDmqceedNCu3VvGI3bqQQn9g2'\n",
        "downloaded = drive.CreateFile({'id': file_id, \"title\":\"kegg.ungraph.pkl\"})\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmDCJqexrWNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "8798375e-9240-4270-bae9-1b773523f6de"
      },
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "G = nx.read_gpickle(\"/content/drive/My Drive/BDL_project/kegg.ungraph.pkl\")\n",
        "for n in G.nodes:\n",
        "    print(\"Fingerprints for node %s: %r\" % (n, G.nodes[n][\"fingerprint\"]))\n",
        "    break"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fingerprints for node C00013: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
            "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LiB6j9qcB4L7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install torch\n",
        "\n",
        "NOTE:\n",
        "Compared to the reference VAE implementation, the main difference is in the calc_vi_loss function\n",
        "where the likelihood term has been augmented with the loss term to reconstruct the adjacency matrix\n"
      ]
    },
    {
      "metadata": {
        "id": "jHLhxy06GNQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the necssary packages\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IdhSSbsHzrsB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Standard VAE class"
      ]
    },
    {
      "metadata": {
        "id": "sYNQvpF8AQYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_dims_code=16,\n",
        "            n_dims_data=32,\n",
        "            hidden_layer_sizes=[32],\n",
        "            encoder=True,):\n",
        "        \n",
        "        \"\"\"\n",
        "        q_sigma = 0.2\n",
        "        \"\"\"\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        self.n_dims_data = n_dims_data\n",
        "        self.n_dims_code = n_dims_code\n",
        "        layer_sizes = (\n",
        "            [n_dims_data] + hidden_layer_sizes + [n_dims_code]\n",
        "        )\n",
        "        self.n_layers = len(layer_sizes) - 1\n",
        "\n",
        "        if not encoder:\n",
        "            layer_sizes = [a for a in reversed(layer_sizes)]\n",
        "\n",
        "        self.activations = list()\n",
        "        self.params = nn.ModuleList()\n",
        "        for (n_in, n_out) in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
        "            self.params.append(nn.Linear(n_in, n_out))\n",
        "            self.activations.append(F.relu)\n",
        "        self.activations[-1] = lambda a: a\n",
        "\n",
        "            \n",
        "    def forward(self, x):\n",
        "        # Note that if x contains multiple instance\n",
        "        # if x.shape = (num_sample, in_dim)\n",
        "        # then the output shape will be (num_sample, out_dim)\n",
        "        cur_arr = x\n",
        "        for ll in range(self.n_layers):\n",
        "            linear_func = self.params[ll]\n",
        "            a_func = self.activations[ll]\n",
        "            cur_arr = a_func(linear_func(cur_arr))\n",
        "        mu_NC = cur_arr\n",
        "        return mu_NC\n",
        "\n",
        "      \n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            q_sigma=0.2,\n",
        "            n_dims_code=16,\n",
        "            n_dims_data=64,\n",
        "            hidden_layer_sizes=[32],\n",
        "            hsp=False\n",
        "    ):\n",
        "\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.n_dims_data = n_dims_data\n",
        "        self.n_dims_code = n_dims_code\n",
        "        self.q_sigma = torch.Tensor([float(q_sigma)])\n",
        "        encoder_layer_sizes = (\n",
        "            [n_dims_data] + hidden_layer_sizes + [n_dims_code]\n",
        "        )\n",
        "        self.n_layers = len(encoder_layer_sizes) - 1\n",
        "        \n",
        "        if not hsp:\n",
        "            # Encoder network\n",
        "            self.encoder = NeuralNetwork(\n",
        "                n_dims_code=n_dims_code,\n",
        "                n_dims_data=n_dims_data,\n",
        "                hidden_layer_sizes=hidden_layer_sizes,\n",
        "                encoder=True,\n",
        "            )\n",
        "            # Decoder network\n",
        "            self.decoder = NeuralNetwork(\n",
        "                n_dims_code=n_dims_code,\n",
        "                n_dims_data=n_dims_data,\n",
        "                hidden_layer_sizes=hidden_layer_sizes,\n",
        "                encoder=False,\n",
        "            )\n",
        "        else:\n",
        "            # TODO: FactorizedInv-Gamma\n",
        "            # Use Ghosh's implementation of the factorizedInv-Gamma inference\n",
        "            # engine or reimplement his code with pytorch\n",
        "            \n",
        "            pass\n",
        "        \n",
        "\n",
        "    def forward(self, x_ND):\n",
        "        \"\"\"\n",
        "        Run entire probabilistic autoencoder on input (encode then decode)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        xproba_ND : 1D array, size of x_ND\n",
        "        \"\"\"\n",
        "        mu_NC = self.encode(x_ND)\n",
        "        z_NC = self.draw_sample_from_q(mu_NC)\n",
        "        return self.decode(z_NC), mu_NC\n",
        "\n",
        "    \n",
        "    def draw_sample_from_q(self, mu_NC):\n",
        "        ''' Draw sample from the probabilistic encoder q(z|mu(x), \\sigma)\n",
        "\n",
        "        We assume that \"q\" is Normal with:\n",
        "        * mean mu (argument of this function)\n",
        "        * stddev q_sigma (attribute of this class, use self.q_sigma)\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "        mu_NC : tensor-like, N x C\n",
        "            Mean of the encoding for each of the N images in minibatch.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        z_NC : tensor-like, N x C\n",
        "            Exactly one sample vector for each of the N images in minibatch.\n",
        "        '''\n",
        "        # Number of samples\n",
        "        N = mu_NC.shape[0]\n",
        "        \n",
        "        # The dimension of the code\n",
        "        C = self.n_dims_code\n",
        "\n",
        "        if self.training:\n",
        "            # Draw standard normal samples \"epsilon\"\n",
        "            # Use the reparameterization trick\n",
        "            eps_NC = torch.randn(N, C)\n",
        "            z_NC = mu_NC + eps_NC * self.q_sigma\n",
        "            return z_NC\n",
        "        else:\n",
        "            # For evaluations, we always just use the mean\n",
        "            return mu_NC\n",
        "\n",
        "    def encode(self, x_ND):\n",
        "        \"\"\"\n",
        "        Args\n",
        "        ----\n",
        "        x_ND: the observation vector\n",
        "        \"\"\"\n",
        "        return self.encoder.forward(x_ND)\n",
        "\n",
        "    def decode(self, z_NC):\n",
        "        \"\"\"\n",
        "        Args\n",
        "        ----\n",
        "        z_NC: the code vector\n",
        "        \"\"\"\n",
        "        return self.decoder.forward(z_NC)\n",
        "\n",
        "    def binary_predict_error_rate(self, f_predict, f_true):\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        length = f_predict.size()[0]\n",
        "        f_predict_binary = (f_predict > 0.5).type(torch.FloatTensor)\n",
        "        error = torch.sum((f_predict_binary - f_true).abs_()) / length\n",
        "        return error\n",
        "\n",
        "    def calc_vi_loss(self, xs_ND, ys_ND, vals, n_mc_samples=1):\n",
        "        \"\"\"\n",
        "        Args\n",
        "\n",
        "        xs_ND: the input feature vectors\n",
        "        ys_ND: the other feature vectors in mini-batch\n",
        "        vals: the entry associated with (x,y)\n",
        "        n_mc_samples: \n",
        "\n",
        "        ----\n",
        "        Returns:\n",
        "        loss\n",
        "\n",
        "        \"\"\"\n",
        "        neg_expected_ll = 0.0\n",
        "        # Given a (potentially) a tensor of observation vectors, \n",
        "        # Encode it into latent space\n",
        "        mx_NC = self.encode(xs_ND)\n",
        "        my_NC = self.encode(ys_ND)\n",
        "        \n",
        "        # Compute the KL divergence\n",
        "        # KL(N(mx_NC, q_sigma) || N(0, I))\n",
        "        kl_xz_NC = -0.5 * torch.sum(1 + torch.log(self.q_sigma ** 2) - mx_NC ** 2 - self.q_sigma ** 2)\n",
        "        kl_yz_NC = -0.5 * torch.sum(1 + torch.log(self.q_sigma ** 2) - my_NC ** 2 - self.q_sigma ** 2)\n",
        "        kl       = kl_xz_NC + kl_yz_NC # Total KL term\n",
        "        \n",
        "        # Generate samples from N(mx_NC, q_sigma) to compute the following\n",
        "        # E_q[log p(x_ND|mx_NC)]\n",
        "        for ss in range(n_mc_samples):\n",
        "            sample_z_NC      = self.draw_sample_from_q(mx_NC)\n",
        "            sample_xproba_ND = self.decode(sample_z_NC)\n",
        "\n",
        "            # Use MSE to measure reconstruction loss\n",
        "            # Since MSE is equivalent to log gaussian loss\n",
        "            sample_mse_loss  = F.mse_loss(sample_xproba_ND, xs_ND)\n",
        "\n",
        "            # KL divergence from q(mu, sigma) to prior (std normal)\n",
        "            neg_expected_ll += 1/n_mc_samples * sample_mse_loss\n",
        "        \n",
        "        \n",
        "        # Compute the loss from adjacency matrix reconstruction\n",
        "        # Get number of entries\n",
        "        num_samples = len(vals)\n",
        "        f_predict   = torch.zeros(num_samples)\n",
        "\n",
        "        # Compute\n",
        "        # E_q[log p(A_ij|x_i, x_j)] = E_q[Bern(A_ij|sigmoid(x_i dot x_j))]\n",
        "        \n",
        "        for ss in range(n_mc_samples):\n",
        "            # These two should have the same shape\n",
        "            # which is (N*C)\n",
        "            sample_z_NC = self.draw_sample_from_q(mx_NC)\n",
        "            sample_y_NC = self.draw_sample_from_q(my_NC)\n",
        "\n",
        "            # inner_prod.shape = (N,)\n",
        "            inner_prod  = torch.sum(sample_z_NC * sample_y_NC, dim=1)\n",
        "            f_predict  += 1/n_mc_samples * torch.sigmoid(inner_prod)\n",
        "\n",
        "        # Use binary cross entry loss, NOTE that this is for\n",
        "        # adjacency matrix whose entry values are 0 and 1\n",
        "        # This will need to change for other types of adjacency matrix value\n",
        "        # Use the binary prediction loss with logits\n",
        "        matrix_reconstruction_loss = \\\n",
        "            F.binary_cross_entropy(f_predict, Variable(torch.FloatTensor(vals)), reduction='sum')\n",
        "        \n",
        "        neg_expected_ll += matrix_reconstruction_loss\n",
        "        \n",
        "        return neg_expected_ll, kl, matrix_reconstruction_loss, sample_xproba_ND\n",
        "      \n",
        "      \n",
        "\n",
        "class VariationalAutoencoderHSP(VariationalAutoencoder):\n",
        "    def __init__(self,inference_engine,**kwargs,):\n",
        "\n",
        "        super(VariationalAutoencoderHSP, self).__init__(**kwargs)\n",
        "        assert inference_engine\n",
        "        self.inference_engine = inference_engine\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qOLmcpS_0MJE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# VAE with horseshoe priors"
      ]
    },
    {
      "metadata": {
        "id": "1cydvYRB0OqL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" Uses a non-centered parameterization of the model.\n",
        "    Fully factorized Gaussian + IGamma Variational distribution\n",
        "\tq = N(w_ijl | m_ijl, sigma^2_ijl) N(ln \\tau_kl | params) IGamma(\\lambda_kl| params)\n",
        "\tIGamma(\\tau_l | params) IGamma(\\lambda_l| params)\n",
        "\"\"\"\n",
        "\n",
        "import autograd.numpy as np\n",
        "import autograd.numpy.random as npr\n",
        "from autograd.scipy.misc import logsumexp\n",
        "from autograd.scipy.special import gammaln, psi\n",
        "from src.utility_functions import diag_gaussian_entropy, inv_gamma_entropy, log_normal_entropy\n",
        "\n",
        "\n",
        "class FactorizedHierarchicalInvGamma:\n",
        "    def __init__(self, n_weights, lambda_a, lambda_b, lambda_b_global, tau_a, shapes, train_stats, classification=False,\n",
        "                 n_data=None):\n",
        "        self.name = \"Factorized Hierarchical Inverse Gamma Variational Approximation\"\n",
        "        self.classification = classification\n",
        "        self.n_weights = n_weights\n",
        "        self.shapes = shapes\n",
        "        self.num_hidden_layers = len(shapes) - 1\n",
        "        self.lambda_a_prior = lambda_a\n",
        "        self.lambda_b_prior = lambda_b\n",
        "        self.lambda_a_prior_global = 0.5\n",
        "        self.lambda_b_prior_global = lambda_b_global\n",
        "        self.lambda_a_prior_oplayer = 0.5\n",
        "        self.lambda_b_prior_oplayer = 1.\n",
        "        self.tau_a_prior = tau_a\n",
        "        self.tau_a_prior_global = 0.5\n",
        "        self.tau_a_prior_oplayer = 0.5\n",
        "        self.l2pi = np.log(2 * np.pi)\n",
        "        self.n_data = n_data\n",
        "        self.noise_entropy = None\n",
        "        if not self.classification:\n",
        "            # gamma(6, 6) prior on precision\n",
        "            self.noise_a = 6.\n",
        "            self.noise_b = 6.\n",
        "            self.train_stats = train_stats\n",
        "\n",
        "    ######### PACK UNPACK PARAMS #################################################\n",
        "    def initialize_variational_params(self, param_scale=1):\n",
        "        # Initialize weights\n",
        "        wlist = list()\n",
        "        for m, n in self.shapes:\n",
        "            wlist.append(npr.randn(m * n) * np.sqrt(2 / m))\n",
        "            wlist.append(np.zeros(n))  # bias\n",
        "        w = np.concatenate(wlist)\n",
        "        log_sigma = param_scale * npr.randn(w.shape[0]) - 10.\n",
        "        # initialize scale parameters\n",
        "        self.tot_outputs = 0\n",
        "        for _, num_hl_outputs in self.shapes:\n",
        "            self.tot_outputs += num_hl_outputs\n",
        "        # No hs priors on the outputs\n",
        "        self.tot_outputs = self.tot_outputs - self.shapes[-1][1]\n",
        "        if not self.classification:\n",
        "            tau_mu, tau_log_sigma, tau_global_mu, tau_global_log_sigma, tau_oplayer_mu, tau_oplayer_log_sigma, log_a, \\\n",
        "                                log_b = self.initialize_scale_from_prior()\n",
        "            init_params = np.concatenate([w.ravel(), log_sigma.ravel(),\n",
        "                                          tau_mu.ravel(), tau_log_sigma.ravel(), tau_global_mu.ravel(),\n",
        "                                          tau_global_log_sigma.ravel(), tau_oplayer_mu, tau_oplayer_log_sigma, log_a,\n",
        "                                          log_b])\n",
        "        else:\n",
        "            tau_mu, tau_log_sigma, tau_global_mu, tau_global_log_sigma, tau_oplayer_mu, tau_oplayer_log_sigma = \\\n",
        "                self.initialize_scale_from_prior()\n",
        "            init_params = np.concatenate([w.ravel(), log_sigma.ravel(),\n",
        "                                          tau_mu.ravel(), tau_log_sigma.ravel(), tau_global_mu.ravel(),\n",
        "                                          tau_global_log_sigma.ravel(), tau_oplayer_mu, tau_oplayer_log_sigma])\n",
        "\n",
        "        return init_params\n",
        "\n",
        "    def initialize_scale_from_prior(self):\n",
        "        # scale parameters (hidden + observed),\n",
        "        self.lambda_a_hat = (self.tau_a_prior + self.lambda_a_prior) * np.ones([self.tot_outputs, 1]).ravel()\n",
        "        self.lambda_b_hat = (1.0 / self.lambda_b_prior ** 2) * np.ones([self.tot_outputs, 1]).ravel()\n",
        "        self.lambda_a_hat_global = (self.tau_a_prior_global + self.lambda_a_prior_global)  \\\n",
        "            * np.ones([self.num_hidden_layers, 1]).ravel()\n",
        "        self.lambda_b_hat_global = (1.0 / self.lambda_b_prior_global ** 2) * np.ones(\n",
        "            [self.num_hidden_layers, 1]).ravel()\n",
        "        # set oplayer lambda param\n",
        "        self.lambda_a_hat_oplayer = np.array(self.tau_a_prior_oplayer + self.lambda_a_prior_oplayer).reshape(-1)\n",
        "        self.lambda_b_hat_oplayer = (1.0 / self.lambda_b_prior_oplayer ** 2) * np.ones([1]).ravel()\n",
        "        # sample from half cauchy and log to initialize the mean of the log normal\n",
        "        sample = np.abs(self.lambda_b_prior * (npr.randn(self.tot_outputs) / npr.randn(self.tot_outputs)))\n",
        "        tau_mu = np.log(sample)\n",
        "        tau_log_sigma = npr.randn(self.tot_outputs) - 10.\n",
        "        # one tau_global for each hidden layer\n",
        "        sample = np.abs(\n",
        "            self.lambda_b_prior_global * (npr.randn(self.num_hidden_layers) / npr.randn(self.num_hidden_layers)))\n",
        "        tau_global_mu = np.log(sample)\n",
        "        tau_global_log_sigma = npr.randn(self.num_hidden_layers) - 10.\n",
        "        # one tau for all op layer weights\n",
        "        sample = np.abs(self.lambda_b_hat_oplayer * (npr.randn() / npr.randn()))\n",
        "        tau_oplayer_mu = np.log(sample)\n",
        "        tau_oplayer_log_sigma = npr.randn(1) - 10.\n",
        "        if not self.classification:\n",
        "            log_a = np.array(np.log(self.noise_a)).reshape(-1)\n",
        "            log_b = np.array(np.log(self.noise_b)).reshape(-1)\n",
        "            return tau_mu, tau_log_sigma, tau_global_mu, tau_global_log_sigma, tau_oplayer_mu, tau_oplayer_log_sigma, \\\n",
        "                   log_a, log_b\n",
        "        else:\n",
        "            return tau_mu, tau_log_sigma, tau_global_mu, tau_global_log_sigma, tau_oplayer_mu, tau_oplayer_log_sigma\n",
        "\n",
        "    def unpack_params(self, params):\n",
        "        # unpack params\n",
        "        w_vect = params[:self.n_weights]\n",
        "        num_std = 2 * self.n_weights\n",
        "        sigma = np.log(1 + np.exp(params[self.n_weights:num_std]))\n",
        "        tau_mu = params[num_std:num_std + self.tot_outputs]\n",
        "        tau_sigma = np.log(\n",
        "            1 + np.exp(params[num_std + self.tot_outputs:num_std + 2 * self.tot_outputs]))\n",
        "        tau_mu_global = params[num_std + 2 * self.tot_outputs: num_std + 2 * self.tot_outputs + self.num_hidden_layers]\n",
        "        tau_sigma_global = np.log(1 + np.exp(params[num_std + 2 * self.tot_outputs + self.num_hidden_layers:num_std +\n",
        "                                                                    2 * self.tot_outputs + 2 * self.num_hidden_layers]))\n",
        "        tau_mu_oplayer = params[num_std + 2 * self.tot_outputs + 2 * self.num_hidden_layers: num_std +\n",
        "                                                                2 * self.tot_outputs + 2 * self.num_hidden_layers + 1]\n",
        "        tau_sigma_oplayer = np.log(\n",
        "            1 + np.exp(params[num_std + 2 * self.tot_outputs + 2 * self.num_hidden_layers + 1:]))\n",
        "        if not self.classification:\n",
        "            a = tau_sigma_oplayer[1]\n",
        "            b = tau_sigma_oplayer[2]\n",
        "            tau_sigma_oplayer = tau_sigma_oplayer[0]\n",
        "            egamma = a / b\n",
        "            elog_gamma = psi(a) - np.log(b)\n",
        "            self.noise_entropy = inv_gamma_entropy(a, b)\n",
        "            #  we will just use a point estimate of noise_var b/a+1 (noise_var ~ IGamma) for computing predictive ll\n",
        "            self.noisevar = (b / (a + 1)) * self.train_stats['sigma'] ** 2\n",
        "            return w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, \\\n",
        "                   tau_sigma_oplayer, elog_gamma, egamma\n",
        "        else:\n",
        "            return w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer\n",
        "\n",
        "    def unpack_layer_weight_variances(self, sigma_vect):\n",
        "        for m, n in self.shapes:\n",
        "            yield sigma_vect[:m * n].reshape((m, n)), sigma_vect[m * n:m * n + n]\n",
        "            sigma_vect = sigma_vect[(m + 1) * n:]\n",
        "\n",
        "    def unpack_layer_weight_priors(self, tau_vect):\n",
        "        for m, n in self.shapes:\n",
        "            yield tau_vect[:n]\n",
        "            tau_vect = tau_vect[n:]\n",
        "\n",
        "    def unpack_layer_weights(self, w_vect):\n",
        "        for m, n in self.shapes:\n",
        "            yield w_vect[:m * n].reshape((m, n)), w_vect[m * n:m * n + n]\n",
        "            w_vect = w_vect[(m + 1) * n:]\n",
        "\n",
        "    ######### Fixed Point Updates ################################## #####\n",
        "    def fixed_point_updates(self, params):\n",
        "        if self.classification:\n",
        "            w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer = \\\n",
        "                self.unpack_params(params)\n",
        "        else:\n",
        "            w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, _, _ \\\n",
        "                = self.unpack_params(params)\n",
        "        # update lambda moments\n",
        "        self.lambda_b_hat = np.exp(-tau_mu + 0.5 * tau_sigma ** 2) + (1. / self.lambda_b_prior ** 2)\n",
        "        self.lambda_b_hat_global = np.exp(-tau_mu_global + 0.5 * tau_sigma_global ** 2) + (\n",
        "            1. / self.lambda_b_prior_global ** 2)\n",
        "        self.lambda_b_hat_oplayer = np.exp(-tau_mu_oplayer + 0.5 * tau_sigma_oplayer ** 2) + (\n",
        "            1. / self.lambda_b_prior_oplayer ** 2)\n",
        "        return None\n",
        "\n",
        "    ######### ELBO CALC ################################################\n",
        "    def lrpm_forward_pass(self, mu_vect, sigma_vect, tau_mu_vect, tau_sigma_vect, tau_mu_global, tau_sigma_global,\n",
        "                          tau_mu_oplayer, tau_sigma_oplayer, inputs):\n",
        "        for layer_id, (mu, var, tau_mu, tau_sigma) in enumerate(\n",
        "                zip(self.unpack_layer_weights(mu_vect), self.unpack_layer_weight_variances(sigma_vect),\n",
        "                    self.unpack_layer_weight_priors(tau_mu_vect),\n",
        "                    self.unpack_layer_weight_priors(tau_sigma_vect))):\n",
        "            w, b = mu\n",
        "            sigma__w, sigma_b = var\n",
        "            if layer_id < len(self.shapes) - 1:\n",
        "                scale_mu = 0.5 * (tau_mu + tau_mu_global[layer_id])\n",
        "                scale_v = 0.25 * (tau_sigma ** 2 + tau_sigma_global[layer_id] ** 2)\n",
        "                scale = np.exp(scale_mu + np.sqrt(scale_v) * npr.randn(tau_mu.shape[0]))\n",
        "                mu_w = np.dot(inputs, w) + b\n",
        "                v_w = np.dot(inputs ** 2, sigma__w ** 2) + sigma_b ** 2\n",
        "                outputs = (np.sqrt(v_w) / np.sqrt(inputs.shape[1])) * np.random.normal(size=mu_w.shape) + mu_w\n",
        "                outputs = scale * outputs\n",
        "                inputs = outputs * (outputs > 0)\n",
        "            else:\n",
        "                op_scale_mu = 0.5 * tau_mu_oplayer\n",
        "                op_scale_v = 0.25 * tau_sigma_oplayer ** 2\n",
        "                Ekappa_half = np.exp(op_scale_mu + np.sqrt(op_scale_v) * npr.randn())\n",
        "                mu_w = np.dot(inputs, w) + b\n",
        "                v_w = np.dot(inputs ** 2, sigma__w ** 2) + sigma_b ** 2\n",
        "                outputs = Ekappa_half * (np.sqrt(v_w) / np.sqrt(inputs.shape[1])) * np.random.normal(\n",
        "                    size=mu_w.shape) + mu_w\n",
        "        return outputs\n",
        "\n",
        "    def EPw_Gaussian(self, prior_precision, w, sigma):\n",
        "        \"\"\"\"\\int q(z) log p(z) dz, assuming gaussian q(z) and p(z)\"\"\"\n",
        "        wD = w.shape[0]\n",
        "        prior_wvar_ = 1. / prior_precision\n",
        "        a = - 0.5 * wD * np.log(2 * np.pi) - 0.5 * wD * np.log(prior_wvar_) - 0.5 * prior_precision * (\n",
        "            np.dot(w.T, w) + np.sum((sigma ** 2)))\n",
        "        return a\n",
        "\n",
        "    def EP_Gamma(self, Egamma, Elog_gamma):\n",
        "        \"\"\" Enoise precision \"\"\"\n",
        "        return self.noise_a * np.log(self.noise_b) - gammaln(self.noise_a) + (\n",
        "                                                            - self.noise_a - 1) * Elog_gamma - self.noise_b * Egamma\n",
        "\n",
        "    def EPtaulambda(self, tau_mu, tau_sigma, tau_a_prior, lambda_a_prior,\n",
        "                    lambda_b_prior, lambda_a_hat, lambda_b_hat):\n",
        "        \"\"\" E[ln p(\\tau | \\lambda)] + E[ln p(\\lambda)]\"\"\"\n",
        "        etau_given_lambda = -gammaln(tau_a_prior) - tau_a_prior * (np.log(lambda_b_hat) - psi(lambda_a_hat)) + (\n",
        "                            -tau_a_prior - 1.) * tau_mu - np.exp(-tau_mu + 0.5 * tau_sigma ** 2) * (lambda_a_hat /\n",
        "                                               lambda_b_hat)\n",
        "        elambda = -gammaln(lambda_a_prior) - 2 * lambda_a_prior * np.log(lambda_b_prior) + (-lambda_a_prior - 1.) * (\n",
        "            np.log(lambda_b_hat) - psi(lambda_a_hat)) - (1. / lambda_b_prior ** 2) * (lambda_a_hat / lambda_b_hat)\n",
        "        return np.sum(etau_given_lambda) + np.sum(elambda)\n",
        "\n",
        "    def entropy(self, sigma, tau_sigma, tau_mu, tau_sigma_global, tau_mu_global, tau_sigma_oplayer, tau_mu_oplayer):\n",
        "        ent_w = diag_gaussian_entropy(np.log(sigma), self.n_weights)\n",
        "        ent_tau = log_normal_entropy(np.log(tau_sigma), tau_mu, self.tot_outputs) + log_normal_entropy(\n",
        "            np.log(tau_sigma_global), tau_mu_global, self.num_hidden_layers) + log_normal_entropy(\n",
        "            np.log(tau_sigma_oplayer), tau_mu_oplayer, 1)\n",
        "        ent_lambda = inv_gamma_entropy(self.lambda_a_hat, self.lambda_b_hat) + inv_gamma_entropy(\n",
        "            self.lambda_a_hat_global, self.lambda_b_hat_global) + inv_gamma_entropy(self.lambda_a_hat_oplayer,\n",
        "                                                                                    self.lambda_b_hat_oplayer)\n",
        "        return ent_w, ent_tau, ent_lambda\n",
        "\n",
        "    def compute_elbo_contribs(self, params, x, y):\n",
        "        if self.classification:\n",
        "            w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer \\\n",
        "                = self.unpack_params(params)\n",
        "        else:\n",
        "            w_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, \\\n",
        "            Elog_gamma, Egamma = self.unpack_params(params)\n",
        "        preds = self.lrpm_forward_pass(w_vect, sigma, tau_mu, tau_sigma,\n",
        "                                       tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, x)\n",
        "        if self.classification:\n",
        "            preds = preds - logsumexp(preds, axis=1, keepdims=True)\n",
        "            log_lik = np.sum(np.sum(y * preds, axis=1), axis=0)\n",
        "        else:\n",
        "            log_lik = -0.5 * np.sum((preds - y.reshape(-1, 1)) ** 2) * Egamma - 0.5 * preds.shape[0] * self.l2pi \\\n",
        "                      + 0.5 * preds.shape[0] * Elog_gamma\n",
        "\n",
        "        log_prior = self.EPw_Gaussian(1., w_vect, sigma)\n",
        "        log_prior = log_prior + \\\n",
        "                    self.EPtaulambda(tau_mu, tau_sigma, self.tau_a_prior, self.lambda_a_prior, self.lambda_b_prior,\n",
        "                                     self.lambda_a_hat, self.lambda_b_hat) + \\\n",
        "                    self.EPtaulambda(tau_mu_global, tau_sigma_global, self.tau_a_prior_global,\n",
        "                                     self.lambda_a_prior_global, self.lambda_b_prior_global, self.lambda_a_hat_global,\n",
        "                                     self.lambda_b_hat_global) + \\\n",
        "                    self.EPtaulambda(tau_mu_oplayer, tau_sigma_oplayer, self.tau_a_prior_oplayer,\n",
        "                                     self.lambda_a_prior_oplayer, self.lambda_b_prior_oplayer,\n",
        "                                     self.lambda_a_hat_oplayer, self.lambda_b_hat_oplayer)\n",
        "        ent_w, ent_tau, ent_lambda = self.entropy(sigma, tau_sigma, tau_mu, tau_sigma_global, tau_mu_global,\n",
        "                                                  tau_sigma_oplayer, tau_mu_oplayer)\n",
        "\n",
        "        if not self.classification:\n",
        "            log_prior = log_prior + self.EP_Gamma(Egamma, Elog_gamma)\n",
        "            ent_lambda = ent_lambda + self.noise_entropy  # hack add it to lambda entropy\n",
        "        return log_lik, log_prior, ent_w, ent_tau, ent_lambda\n",
        "\n",
        "\n",
        "    def compute_train_err(self, params, X, y):\n",
        "        if self.classification:\n",
        "            W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer = \\\n",
        "                self.unpack_params(params)\n",
        "        else:\n",
        "            W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, _, _ \\\n",
        "                = self.unpack_params(params)\n",
        "        preds = self.lrpm_forward_pass(W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global,\n",
        "                                       tau_mu_oplayer, tau_sigma_oplayer, X)\n",
        "        if self.classification:\n",
        "            preds = np.exp(preds - logsumexp(preds, axis=1, keepdims=True))\n",
        "            tru_labels = np.argmax(y, axis=1)\n",
        "            pred_labels = np.argmax(preds, axis=1)\n",
        "            err_ids = tru_labels != pred_labels\n",
        "            return 1. * np.sum(err_ids) / y.shape[0]\n",
        "        else:\n",
        "            return np.sqrt(np.mean((preds - y.reshape(-1, 1)) ** 2))\n",
        "\n",
        "    def compute_test_ll(self, params, x, y_test, num_samples=1):\n",
        "        if self.classification:\n",
        "            W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer = \\\n",
        "                self.unpack_params(params)\n",
        "        else:\n",
        "            W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global, tau_mu_oplayer, tau_sigma_oplayer, \\\n",
        "            Elog_gamma, Egamma = self.unpack_params(params)\n",
        "        err_rate = 0.\n",
        "        test_ll = np.zeros([num_samples, y_test.shape[0]])\n",
        "        test_ll_dict = dict()\n",
        "        for i in np.arange(num_samples):\n",
        "            y = self.lrpm_forward_pass(W_vect, sigma, tau_mu, tau_sigma, tau_mu_global, tau_sigma_global,\n",
        "                                       tau_mu_oplayer, tau_sigma_oplayer, x)\n",
        "            if y_test.ndim == 1:\n",
        "                y = y.ravel()\n",
        "            if self.classification:\n",
        "                yraw = y - logsumexp(y, axis=1, keepdims=True)\n",
        "                y = np.exp(yraw)\n",
        "                tru_labels = np.argmax(y_test, axis=1)\n",
        "                pred_labels = np.argmax(y, axis=1)\n",
        "                err_ids = tru_labels != pred_labels\n",
        "                err_rate = err_rate + np.sum(err_ids) / y_test.shape[0]\n",
        "                # test_ll is scaled by number of test_points\n",
        "                test_ll[i] = np.mean(np.sum(y_test * np.log(y + 1e-32), axis=1))\n",
        "            else:\n",
        "                # scale by target stats\n",
        "                y_scaled = y * self.train_stats['sigma'] + self.train_stats['mu']\n",
        "                # rmse\n",
        "                err_rate = err_rate + np.sqrt(np.mean((y_test - y_scaled) ** 2))\n",
        "                test_ll[i] = (-0.5 * (1. / self.noisevar) * (y_test - y_scaled) ** 2 - 0.5 * self.l2pi - 0.5 * np.log(\n",
        "                    self.noisevar)).ravel()\n",
        "\n",
        "        err_rate = err_rate / num_samples\n",
        "        test_ll_dict['mu'] = np.mean(logsumexp(test_ll, axis=0) - np.log(num_samples))\n",
        "        return test_ll_dict, err_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E72JYLr6TbU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Synthetic data generation\n",
        "\n",
        "Synthetic data (and real life data to test on) should include\n",
        "* Adjancency matrix (which might be sparse) where A_{ij} = 1 if there is an edge and 0 otherwise between two nodes i and j\n",
        "* The feature vectors for all the nodes"
      ]
    },
    {
      "metadata": {
        "id": "S8h-eAoXKYTu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_entry_values(coordinates, latent_vectors):\n",
        "    \"\"\"\n",
        "    coordinates: list of coordinates\n",
        "    \n",
        "    \"\"\"\n",
        "    vals    = list()\n",
        "    for i, j in coordinates:\n",
        "        if np.sum(latent_vectors[i] * latent_vectors[j]) > 0:\n",
        "            vals.append(1)\n",
        "        else:\n",
        "            vals.append(0)\n",
        "    return vals\n",
        "    \n",
        "\n",
        "def create_sparse_matrix_list(observed_coordinates, num_nodes, latent_vectors):\n",
        "    \"\"\"\n",
        "    observed_coordinates: list of (row,col) coordinates\n",
        "    num_nodes : int, number of nodes\n",
        "    latent_vectors : latent vectos whose inner products used to determine adjacency\n",
        "    matrix\n",
        "    \n",
        "    ---\n",
        "    return the sparse representation of the adjacency matrix\n",
        "    \n",
        "    \"\"\"\n",
        "    sparse_adjacency_matrix = [[] for _ in range(num_nodes)]\n",
        "\n",
        "    for entry in observed_coordinates:\n",
        "        idx, idy = entry[0], entry[1]\n",
        "        inner = np.dot(latent_vectors[idx, :], latent_vectors[idy, :])\n",
        "        val = 0\n",
        "        if inner > 0:\n",
        "            val = 1\n",
        "\n",
        "        sparse_adjacency_matrix[idx].append((entry, val))\n",
        "        sparse_adjacency_matrix[idy].append(([idy, idx], val))\n",
        "\n",
        "    return sparse_adjacency_matrix\n",
        "\n",
        "\n",
        "def create_observed_features(latent_vectors, num_nodes, true_dim, observed_dim, noise_feature_num=0):\n",
        "    \"\"\"    \n",
        "    latent_vectors : shape(num_nodes, true_dim), the latent feature vectors of all nodes\n",
        "    num_nodes : int, number of nodes in this network\n",
        "    true_dim  : int, dimension of the latent feature (the code)\n",
        "    observed_dim : int, dimension of the observed feature vector\n",
        "    num_noisy_dim : int, added noisy dimension\n",
        "    \n",
        "    ---\n",
        "    \n",
        "    Create observed features that contain both true and noisy features\n",
        "\n",
        "    1. Create a random transformation matrix A\n",
        "    2. Apply the transformation A X_l where X_l is the latent feature vectors\n",
        "    3. \n",
        "    ---\n",
        "    returns\n",
        "    \n",
        "    augmented_feature_matrix : shape(num_nodes, observed_dim + num_noisy_dim)\n",
        "    the augmented observed feature vector for all the nodes, with relevent\n",
        "    dimensions together with noisy entries.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Create a random transformation, A\n",
        "    transformation_matrix = np.random.randn(observed_dim, true_dim)\n",
        "\n",
        "    # X_true = dot(A, x_true)\n",
        "    transformed_feature = np.dot(transformation_matrix, latent_vectors.T)\n",
        "    transformed_feature = transformed_feature.T\n",
        "    transformed_feature /= transformed_feature.max()  # Scale the feature vectors by dividing by the max value\n",
        "\n",
        "    # If no noisy feature, just return the transformed feature\n",
        "    if noise_feature_num == 0:\n",
        "        return transformed_feature\n",
        "    \n",
        "    # If there are noisy features, generate these from standard normal distribution\n",
        "    # Noise feature = N(0, I)\n",
        "    # Create noise matrix X_noise\n",
        "    noise_feature_matrix = np.random.randn(num_nodes, noise_feature_num)\n",
        "    augmented_dim = observed_dim + noise_feature_num\n",
        "\n",
        "    # Horizontally concatenate X_true :: X_noise\n",
        "    augmented_feature_matrix = np.hstack((transformed_feature, noise_feature_matrix))\n",
        "\n",
        "    # Permute the features column\n",
        "    augmented_feature_matrix = augmented_feature_matrix[:, np.random.permutation(augmented_dim)]\n",
        "    return augmented_feature_matrix\n",
        "\n",
        "\n",
        "def create_synthetic_data(num_nodes, sparsity, true_dim, observed_dim, num_noisy_dim):\n",
        "    \"\"\"\n",
        "    num_nodes : int, number of nodes in this network\n",
        "    sparsity  : float, ratio of all entries, which are observed\n",
        "    true_dim  : int, dimension of the latent feature (the code)\n",
        "    observed_dim : int, dimension of the observed feature vector\n",
        "    num_noisy_dim : int, added noisy dimension\n",
        "    \n",
        "    --- \n",
        "    returns\n",
        "    \n",
        "    (latent_vectors, observed_feature_vectors, sparse_adjancency_matrix)\n",
        "    \n",
        "    latent_vectors : shape(num_nodes, true_dim), all the latent feature vectors\n",
        "    observed_feature_vectors : shape(num_nodes, observed_dim), all the observed feature vectors\n",
        "    sparse_adjancency_matrix : list[list(entry, value)] \n",
        "    \n",
        "    \"\"\"\n",
        "    # Create num_nodes hidden vector randomly\n",
        "    latent_vectors = np.random.multivariate_normal(np.zeros((true_dim,)), \\\n",
        "                                                   np.eye(true_dim), \\\n",
        "                                                   size=(num_nodes,))\n",
        "\n",
        "    coordinates = [[x,y] for x in range(num_nodes) for y in range(x+1, num_nodes)]\n",
        "    total_num_pairs = len(coordinates)\n",
        "    num_observed = int(len(coordinates) * sparsity)\n",
        "\n",
        "    # Pick a number of random coordinates\n",
        "    observed_idx = np.random.choice(total_num_pairs, num_observed, replace=False)\n",
        "    observed_coordinates = np.take(coordinates, observed_idx, axis=0)\n",
        "    \n",
        "    train_size = int(len(observed_coordinates) * 0.8)\n",
        "    train_coordinates = observed_coordinates[:train_size]\n",
        "    test_coordinates = observed_coordinates[train_size+1:]\n",
        "    \n",
        "    # Create sparse matrix representation\n",
        "    train_sparse_adjacency_matrix = create_sparse_matrix_list(train_coordinates, num_nodes, latent_vectors)\n",
        "    test_sparse_adjacency_matrix = create_sparse_matrix_list(test_coordinates, num_nodes, latent_vectors)\n",
        "    \n",
        "    # Create test matrix and train matrix\n",
        "    observed_feature_vectors = create_observed_features(latent_vectors, num_nodes, true_dim, observed_dim,\n",
        "                                                        num_noisy_dim)\n",
        "\n",
        "    return latent_vectors, observed_feature_vectors, train_sparse_adjacency_matrix, test_sparse_adjacency_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vr8CH4BrKL6v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Do training\n",
        "\n",
        "TODO:\n",
        "* Update the training function, first generate synthetic data, organize into batches\n",
        "* Compare between round-robin updates (aka update each row by row where the list of observations always share a common row index) vs mini-batch update where the list of observations can contain any random pair of two indices.\n"
      ]
    },
    {
      "metadata": {
        "id": "_xDkRxRa3mI4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation function"
      ]
    },
    {
      "metadata": {
        "id": "jBpBZKEVQuiX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to do evaluation\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def classification_accuracy(model, feature_tensor, adjacency_matrix, report=False):\n",
        "    \"\"\"\n",
        "    Feature vectors.shape -> (num_nodes, number of observed features)\n",
        "    adjancency_matrix -> sparse representation of adjancey matrix\n",
        "    where each row -> list of (coordinates, value) associated with the specific\n",
        "    factor\n",
        "\n",
        "    Uses model.encode(feature_vector)\n",
        "    \"\"\"\n",
        "    latent_vectors = model.encode(feature_tensor)\n",
        "    latent_adj_mat = torch.mm(latent_vectors, latent_vectors.transpose(0 , 1))\n",
        "    num_accurate = 0.0\n",
        "    num_observed = 0.0\n",
        "    for row in adjacency_matrix:\n",
        "        for coor, val in row:\n",
        "            if (\n",
        "                latent_adj_mat[coor[0]][coor[1]].item() < 0.0 and val == 0.0 or\n",
        "                latent_adj_mat[coor[0]][coor[1]].item() >= 0.0 and val == 1.0\n",
        "            ):\n",
        "\n",
        "                if report:\n",
        "                    print(\"predict: \", latent_adj_mat[coor[0]][coor[1]].item(), \" val: \", val)\n",
        "\n",
        "                num_accurate += 1\n",
        "            num_observed += 1\n",
        "\n",
        "    return num_accurate/ num_observed\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bt80bWYI3pHq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "EJ4zwglopm5E",
        "colab_type": "code",
        "outputId": "d865fc14-cee1-489b-9026-285261daec09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1338
        }
      },
      "cell_type": "code",
      "source": [
        "def train_on_synthetic_data(model, num_nodes, observed_dim, true_dim, fake_dim):\n",
        "    sparsity = 0.25\n",
        "    true_vectors, feature_vectors, train_adjacency_matrix, test_adjacency_matrix\\\n",
        "                = create_synthetic_data(num_nodes, sparsity, true_dim, observed_dim,\n",
        "                                                                            fake_dim)\n",
        "\n",
        "    # NOTE that there exists the 'interchangeability problem'\n",
        "    # XR^TRX = X^TX\n",
        "    # Y = XR^T\n",
        "    \n",
        "    # Initialize optimizer\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    ELBOs = []\n",
        "    epochs = []\n",
        "    all_epochs = []\n",
        "\n",
        "    for epoch in range(1001): \n",
        "        # Do round-robin optimization\n",
        "        for idx in range(num_nodes):\n",
        "            x_ND = Variable(torch.FloatTensor([feature_vectors[idx, :]]))\n",
        "            ys_ND = list()\n",
        "            observed_entries = train_adjacency_matrix[idx]\n",
        "            other_vec_idx = [entry[0][1] for entry in observed_entries]\n",
        "            vals = [entry[1] for entry in observed_entries]\n",
        "\n",
        "            for idy in other_vec_idx:\n",
        "                ys_ND.append(feature_vectors[idy, :])\n",
        "\n",
        "            ys_ND = Variable(torch.FloatTensor(ys_ND))\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # NOTE:\n",
        "            # expected_ll refers to the expected log likelihood term of ELBO\n",
        "            # kl refers to the KL divergence term of the ELBO\n",
        "            # matrix_loss refers to the matrix reconstruction loss\n",
        "            neg_expected_ll, KL, matrix_loss, _ = model.calc_vi_loss(x_ND, ys_ND, vals, n_mc_samples=10)\n",
        "            \n",
        "            KL = 1/len(observed_entries) * KL\n",
        "            # TODO: scale the KL term\n",
        "            # ELBO loss = negative expected log likelihood + KL\n",
        "            elbo_loss = neg_expected_ll + KL\n",
        "            \n",
        "            elbo_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        if epoch % 10 == 0:\n",
        "            all_epochs.append(epoch)\n",
        "            ELBOs.append(-elbo_loss)\n",
        "            \n",
        "\n",
        "        if epoch in [0, 1, 25] or epoch % 50 == 0:\n",
        "            all_vectors = Variable(torch.FloatTensor(feature_vectors))\n",
        "            train_accuracy = classification_accuracy(model, all_vectors, train_adjacency_matrix)\n",
        "            test_accuracy = classification_accuracy(model, all_vectors, test_adjacency_matrix)\n",
        "            epochs.append(epoch)\n",
        "            train_losses.append(train_accuracy)\n",
        "            test_losses.append(test_accuracy)\n",
        "            \n",
        "            print(\"epoch: \", epoch, \" - objective loss: \", np.around(elbo_loss.data.item(),4), \" - train accuracy: \",\n",
        "                  np.around(train_accuracy,4), \" - test accuracy: \", np.around(test_accuracy, 4))\n",
        "\n",
        "\n",
        "    plt.plot(epochs, train_losses, '-', color='b', label='Link predict accuracy on train data')\n",
        "    plt.plot(epochs, test_losses, '--', color='r', label='Link predict accuracy on test data')\n",
        "    plt.ylim((0, 1))\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(all_epochs, ELBOs, '-', color='r', label='ELBO')\n",
        "    plt.ylabel('ELBO value')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "num_nodes = 100\n",
        "observed_dim = 10\n",
        "true_dim = 3\n",
        "num_fake_dim = 5\n",
        "\n",
        "hidden_layer_sizes = [300]\n",
        "naive_model = VariationalAutoencoder(n_dims_code=5, \\\n",
        "                               n_dims_data=observed_dim+num_fake_dim, \\\n",
        "                               hidden_layer_sizes=hidden_layer_sizes)\n",
        "\n",
        "train_on_synthetic_data(naive_model, num_nodes, observed_dim, true_dim, num_fake_dim)\n",
        "\n",
        "# inference_engine = FactorizedHierarchicalInvGamma\n",
        "# hsbnn_model = VariationalAutoencoderHSP(inference_engine,\n",
        "#                                n_dims_code=5, \\\n",
        "#                                n_dims_data=observed_dim+num_fake_dim, \\\n",
        "#                                hidden_layer_sizes=hidden_layer_sizes)\n",
        "# train_on_synthetic_data(hsbnn_model, num_nodes, observed_dim, true_dim, num_fake_dim)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0  - objective loss:  23.1623  - train accuracy:  0.7735  - test accuracy:  0.7368\n",
            "epoch:  1  - objective loss:  21.163  - train accuracy:  0.8241  - test accuracy:  0.8178\n",
            "epoch:  25  - objective loss:  15.4048  - train accuracy:  0.9535  - test accuracy:  0.915\n",
            "epoch:  50  - objective loss:  14.2005  - train accuracy:  0.9575  - test accuracy:  0.9109\n",
            "epoch:  100  - objective loss:  13.836  - train accuracy:  0.9727  - test accuracy:  0.915\n",
            "epoch:  150  - objective loss:  12.5918  - train accuracy:  0.9737  - test accuracy:  0.8907\n",
            "epoch:  200  - objective loss:  12.6197  - train accuracy:  0.9909  - test accuracy:  0.8947\n",
            "epoch:  250  - objective loss:  12.8238  - train accuracy:  0.9899  - test accuracy:  0.8988\n",
            "epoch:  300  - objective loss:  12.8474  - train accuracy:  0.9869  - test accuracy:  0.8907\n",
            "epoch:  350  - objective loss:  12.7671  - train accuracy:  0.9919  - test accuracy:  0.8826\n",
            "epoch:  400  - objective loss:  12.8622  - train accuracy:  0.9889  - test accuracy:  0.8785\n",
            "epoch:  450  - objective loss:  12.8119  - train accuracy:  0.9919  - test accuracy:  0.8785\n",
            "epoch:  500  - objective loss:  12.6062  - train accuracy:  0.9909  - test accuracy:  0.8866\n",
            "epoch:  550  - objective loss:  12.7048  - train accuracy:  0.9869  - test accuracy:  0.8826\n",
            "epoch:  600  - objective loss:  12.8534  - train accuracy:  0.9889  - test accuracy:  0.8583\n",
            "epoch:  650  - objective loss:  12.4422  - train accuracy:  0.9939  - test accuracy:  0.8745\n",
            "epoch:  700  - objective loss:  12.7772  - train accuracy:  0.9949  - test accuracy:  0.8623\n",
            "epoch:  750  - objective loss:  12.2515  - train accuracy:  0.9919  - test accuracy:  0.8704\n",
            "epoch:  800  - objective loss:  12.6255  - train accuracy:  0.9869  - test accuracy:  0.8543\n",
            "epoch:  850  - objective loss:  12.9739  - train accuracy:  0.9899  - test accuracy:  0.8745\n",
            "epoch:  900  - objective loss:  12.8897  - train accuracy:  0.9889  - test accuracy:  0.8502\n",
            "epoch:  950  - objective loss:  12.6857  - train accuracy:  0.9879  - test accuracy:  0.8664\n",
            "epoch:  1000  - objective loss:  12.5097  - train accuracy:  0.9929  - test accuracy:  0.8664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFcCAYAAADh1zYWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ffad9c3f860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFYCAYAAACoFn5YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ffad70d73c8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VariationalAutoencoder(\n",
              "  (encoder): NeuralNetwork(\n",
              "    (params): ModuleList(\n",
              "      (0): Linear(in_features=15, out_features=300, bias=True)\n",
              "      (1): Linear(in_features=300, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): NeuralNetwork(\n",
              "    (params): ModuleList(\n",
              "      (0): Linear(in_features=5, out_features=300, bias=True)\n",
              "      (1): Linear(in_features=300, out_features=15, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}